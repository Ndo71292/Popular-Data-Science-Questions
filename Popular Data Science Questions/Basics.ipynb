{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Popular Data Science Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science Stack Exchange is a question and answer site for Data science professionals, Machine Learning specialists, and those interested in learning more about the field\n",
    "\n",
    "This site is all about getting answers. It's not a discussion forum. There's no chit-chat.\n",
    "\n",
    "The site has the following guidelines:\n",
    "1. Focus on questions about an actual problem you have faced. Include details about what you have tried and exactly what you are trying to do.\n",
    "\n",
    "2. Avoid questions that are primarily opinion-based, or that are likely to generate discussion rather than answers\n",
    "\n",
    "The site also subdivide into \n",
    "Teams - for collaboration and sharing organizational knowledge\n",
    "\n",
    "Users- Proffessional willing to help and share answers\n",
    "\n",
    "Companies- How its like working for different companies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to other Stack Exchange sites, Data Science Stack Exchange (DSSE for short) specialises in Data Science.\n",
    "\n",
    "DSSE also has a high percentage of unanswered questions: A complete list of Stack Exchange websites can be found here, sorted based on the proportion of answered questions. At the time of this writing, Data Science Stack Exchange (DSSE) is one of the bottom ten sites, having only 65% of its questions answered.\n",
    "\n",
    "The data science specialisation and a high percentage of unanswered questions make DSSE the ideal candidate for our investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Stack Exchange provides a public data base for each of its websites\n",
    "\n",
    "read more about Stack Exchange Data Explorer (SEDE) on its help section and on https://data.stackexchange.com/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEDE: The Stack Exchange Data Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Exchange provides a public database for each of its websites.  It is important to note that the database is designed to be queried with the Transact-SQL (Microsoft's SQL) dialect.\n",
    "\n",
    "After exploring the database, we found a few tables that seem relevant to our analysis:\n",
    "\n",
    "Posts: \n",
    "Contains comprehensive information about posts, including the creation date, tags, number of answers, views and upvotes among many more.\n",
    "\n",
    "Tags: \n",
    "Holds information about different tags including the number of times they have been used on the site. However, it does not provide time-series information to help us identify if a tag was popular in the past or present.\n",
    "\n",
    "PostTags: \n",
    "Contains information on posts and their tags alone. Similar to the Tags table, time series information is absent.\n",
    "\n",
    "TagSynonyms: \n",
    "Provides information on tags and alternative names assigned to them by site administrators. Time series information is absent.\n",
    "\n",
    "Given the absence of time-series information in the Tags, PostTags and TagSynonyms tables, and considering that the Posts table already contains the relevant details about tags, we will use the information in the Posts table alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Posts Table\n",
    "\n",
    "The Posts Table has 23 columns. We will focus only on those that seem relevant to our goal:\n",
    "\n",
    "(1.) Id: An identification number for each post.\n",
    "(2.) PostTypeId: An identification number for the type of post.\n",
    "\n",
    "(3.) CreationDate: The date and time of creation of the post.\n",
    "(4.) Score: The post's score.\n",
    "(5.) ViewCount: How many times the post was viewed.\n",
    "(6.) Tags: What tags were used.\n",
    "(7.) AnswerCount: How many answers the question got (only applicable to question posts).\n",
    "(8.) FavoriteCount: How many times the question was favored.\n",
    "\n",
    "We are primarily interested with posts that are questions. Other post types are not relevant at the moment. Before proceeding, we can check how many posts on the site are questions, relative to other posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with the exception of the tags column, the last few columns contain information about how popular the post is — the kind of information we're after.\n",
    "\n",
    "There are eight different types of post. Before we try to figure out which of them are relevant to us, let's check how many of them there are using the query below\n",
    "\n",
    "SELECT PostTypeId, COUNT(*) as NrOfPosts\n",
    "  FROM posts\n",
    " GROUP BY PostTypeId;\n",
    " \n",
    " Results:\n",
    " \n",
    "PostTypeId\tNrOfPosts\n",
    "1\t         21446\n",
    "2\t         23673\n",
    "4\t         236\n",
    "5\t         236\n",
    "6\t         11\n",
    "7\t         1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to their low volume, anything that isn't questions or answers is mostly inconsequential. Even if it happens to be the case that such kind of posts is immensely popular, they would just be outliers and not relevant to us. We'll then just focus on the questions.\n",
    "\n",
    "Since we're only interested in recent posts, we'll limit our analysis to the posts of 2019. (At the time of writing it is early 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set default attributes for charts or graphs\n",
    "%matplotlib\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({'font.family':'Arial'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\"2019_questions.csv\", parse_dates=['CreationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8839 entries, 0 to 8838\n",
      "Data columns (total 7 columns):\n",
      "Id               8839 non-null int64\n",
      "CreationDate     8839 non-null datetime64[ns]\n",
      "Score            8839 non-null int64\n",
      "ViewCount        8839 non-null int64\n",
      "Tags             8839 non-null object\n",
      "AnswerCount      8839 non-null int64\n",
      "FavoriteCount    1407 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(1)\n",
      "memory usage: 483.5+ KB\n"
     ]
    }
   ],
   "source": [
    "questions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>55699</td>\n",
       "      <td>2019-07-15 14:19:18</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;python&gt;&lt;regression&gt;&lt;feature...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>51154</td>\n",
       "      <td>2019-04-30 04:18:11</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;python&gt;&lt;recommender-system&gt;&lt;pyspark&gt;&lt;metric&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>44617</td>\n",
       "      <td>2019-01-26 19:36:50</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;python&gt;&lt;multilabel-classifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>53814</td>\n",
       "      <td>2019-06-14 18:44:26</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>&lt;nlp&gt;&lt;pytorch&gt;&lt;transformer&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>61983</td>\n",
       "      <td>2019-10-20 09:56:39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;time-series&gt;&lt;algorithms&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        CreationDate  Score  ViewCount  \\\n",
       "8708  55699 2019-07-15 14:19:18      1         77   \n",
       "4616  51154 2019-04-30 04:18:11      0         50   \n",
       "124   44617 2019-01-26 19:36:50      1        150   \n",
       "7110  53814 2019-06-14 18:44:26      1        144   \n",
       "4631  61983 2019-10-20 09:56:39      0          5   \n",
       "\n",
       "                                                   Tags  AnswerCount  \\\n",
       "8708  <machine-learning><python><regression><feature...            2   \n",
       "4616      <python><recommender-system><pyspark><metric>            0   \n",
       "124   <machine-learning><python><multilabel-classifi...            1   \n",
       "7110                        <nlp><pytorch><transformer>            0   \n",
       "4631                          <time-series><algorithms>            0   \n",
       "\n",
       "      FavoriteCount  \n",
       "8708            1.0  \n",
       "4616            0.0  \n",
       "124             NaN  \n",
       "7110            NaN  \n",
       "4631            NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "  \n",
    "The dataset presents some issues that we should resolve before analysis.\n",
    "\n",
    "The FavoriteCount column has missing values and is stored with the wrong datatype.\n",
    "\n",
    "The Tags column contains information about different tags at once, which makes the data untidy at the moment.\n",
    "\n",
    "The wrong datatype assigned to the FavoriteCount column is probably because of the missing values. We can explore the column further to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      7432\n",
       " 1.0      953\n",
       " 2.0      205\n",
       " 0.0      175\n",
       " 3.0       43\n",
       " 4.0       12\n",
       " 5.0        8\n",
       " 6.0        4\n",
       " 7.0        4\n",
       " 11.0       1\n",
       " 8.0        1\n",
       " 16.0       1\n",
       "Name: FavoriteCount, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.FavoriteCount.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asides from the missing values, the majority of the posts have zero favourite counts. Infact, a favorite count was only recorded in one post. It is best to drop the FavouriteCount column, since it adds no additional information to our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The FavoriteCount column adds no extra value, we can drop it from our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_clean = questions_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_clean.drop(columns = \"FavoriteCount\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verify the removal of the favorite count column\n",
    "assert \"FavoriteCount\" not in questions_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44419</td>\n",
       "      <td>2019-01-23 09:21:13</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;data-mining&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44420</td>\n",
       "      <td>2019-01-23 09:34:01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;regression&gt;&lt;linear-regressi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44423</td>\n",
       "      <td>2019-01-23 09:58:41</td>\n",
       "      <td>2</td>\n",
       "      <td>1651</td>\n",
       "      <td>&lt;python&gt;&lt;time-series&gt;&lt;forecast&gt;&lt;forecasting&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44427</td>\n",
       "      <td>2019-01-23 10:57:09</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;scikit-learn&gt;&lt;pca&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44428</td>\n",
       "      <td>2019-01-23 11:02:15</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;dataset&gt;&lt;bigdata&gt;&lt;data&gt;&lt;speech-to-text&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44430</td>\n",
       "      <td>2019-01-23 11:13:32</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>&lt;fuzzy-logic&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44432</td>\n",
       "      <td>2019-01-23 11:17:46</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>&lt;time-series&gt;&lt;anomaly-detection&gt;&lt;online-learning&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44436</td>\n",
       "      <td>2019-01-23 12:49:39</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;matrix-factorisation&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44437</td>\n",
       "      <td>2019-01-23 13:04:11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;correlation&gt;&lt;naive-bayes-classifier&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44438</td>\n",
       "      <td>2019-01-23 13:16:29</td>\n",
       "      <td>0</td>\n",
       "      <td>584</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;python&gt;&lt;deep-learning&gt;&lt;kera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>44439</td>\n",
       "      <td>2019-01-23 13:25:24</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;machine-learning&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44440</td>\n",
       "      <td>2019-01-23 14:04:25</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;theory&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44446</td>\n",
       "      <td>2019-01-23 14:55:08</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;gradient-descent&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44448</td>\n",
       "      <td>2019-01-23 15:34:39</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>&lt;nlp&gt;&lt;clustering&gt;&lt;feature-extraction&gt;&lt;encoding...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44449</td>\n",
       "      <td>2019-01-23 15:36:41</td>\n",
       "      <td>1</td>\n",
       "      <td>1212</td>\n",
       "      <td>&lt;python&gt;&lt;scikit-learn&gt;&lt;pandas&gt;&lt;numpy&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44450</td>\n",
       "      <td>2019-01-23 15:37:08</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>&lt;python&gt;&lt;scikit-learn&gt;&lt;decision-trees&gt;&lt;accurac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44454</td>\n",
       "      <td>2019-01-23 16:56:01</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44456</td>\n",
       "      <td>2019-01-23 17:29:04</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>&lt;python&gt;&lt;deep-learning&gt;&lt;keras&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44460</td>\n",
       "      <td>2019-01-23 18:03:18</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;reinforcement-learning&gt;&lt;q-l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44463</td>\n",
       "      <td>2019-01-23 18:52:32</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;neural-network&gt;&lt;deep-learning&gt;&lt;image-classifi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44465</td>\n",
       "      <td>2019-01-23 21:19:38</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;r&gt;&lt;logistic-regression&gt;&lt;regularization&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44472</td>\n",
       "      <td>2019-01-24 00:10:24</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;time-series&gt;&lt;predictive-mod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44474</td>\n",
       "      <td>2019-01-24 00:43:27</td>\n",
       "      <td>2</td>\n",
       "      <td>1810</td>\n",
       "      <td>&lt;python&gt;&lt;keras&gt;&lt;tensorflow&gt;&lt;gpu&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44476</td>\n",
       "      <td>2019-01-24 04:59:16</td>\n",
       "      <td>1</td>\n",
       "      <td>1779</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;&lt;bigdata&gt;&lt;data-cleaning&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44478</td>\n",
       "      <td>2019-01-24 06:33:12</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;data-cleaning&gt;&lt;logistic-reg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44480</td>\n",
       "      <td>2019-01-24 07:04:40</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;python&gt;&lt;object-detection&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>44482</td>\n",
       "      <td>2019-01-24 07:25:46</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;recommender-system&gt;&lt;supervi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>44483</td>\n",
       "      <td>2019-01-24 07:58:35</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;nlp&gt;&lt;text-mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>44484</td>\n",
       "      <td>2019-01-24 08:17:31</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>&lt;machine-learning-model&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>44489</td>\n",
       "      <td>2019-01-24 09:18:10</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>&lt;xgboost&gt;&lt;apache-spark&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8809</th>\n",
       "      <td>55294</td>\n",
       "      <td>2019-07-08 16:36:30</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;python&gt;&lt;neural-network&gt;&lt;ker...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8810</th>\n",
       "      <td>55784</td>\n",
       "      <td>2019-07-16 14:32:38</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;feature-engineering&gt;&lt;feature-construction&gt;&lt;fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8811</th>\n",
       "      <td>55785</td>\n",
       "      <td>2019-07-16 14:41:40</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>&lt;q-learning&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8812</th>\n",
       "      <td>55787</td>\n",
       "      <td>2019-07-16 15:19:34</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;r&gt;&lt;time-series&gt;&lt;statistics&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8813</th>\n",
       "      <td>55793</td>\n",
       "      <td>2019-07-16 17:45:03</td>\n",
       "      <td>1</td>\n",
       "      <td>612</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;python&gt;&lt;scikit-learn&gt;&lt;numpy&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8814</th>\n",
       "      <td>55795</td>\n",
       "      <td>2019-07-16 19:03:17</td>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;scikit-learn&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8815</th>\n",
       "      <td>55378</td>\n",
       "      <td>2019-07-09 16:22:00</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>&lt;keras&gt;&lt;cnn&gt;&lt;image-recognition&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8816</th>\n",
       "      <td>55379</td>\n",
       "      <td>2019-07-09 16:22:41</td>\n",
       "      <td>-2</td>\n",
       "      <td>37</td>\n",
       "      <td>&lt;regression&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8817</th>\n",
       "      <td>55383</td>\n",
       "      <td>2019-07-09 17:55:42</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>&lt;classification&gt;&lt;feature-selection&gt;&lt;feature-en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8818</th>\n",
       "      <td>55385</td>\n",
       "      <td>2019-07-09 18:03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;lstm&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819</th>\n",
       "      <td>55386</td>\n",
       "      <td>2019-07-09 18:03:05</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;r&gt;&lt;gbm&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8820</th>\n",
       "      <td>55388</td>\n",
       "      <td>2019-07-09 19:17:21</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>&lt;keras&gt;&lt;regression&gt;&lt;xgboost&gt;&lt;loss-function&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>55390</td>\n",
       "      <td>2019-07-09 19:40:40</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;scikit-learn&gt;&lt;random-forest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8822</th>\n",
       "      <td>55391</td>\n",
       "      <td>2019-07-09 20:28:14</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;python&gt;&lt;keras&gt;&lt;tensorflow&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8823</th>\n",
       "      <td>55396</td>\n",
       "      <td>2019-07-10 01:38:04</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;cnn&gt;&lt;data-augmentation&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8824</th>\n",
       "      <td>55397</td>\n",
       "      <td>2019-07-10 02:34:22</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;regression&gt;&lt;random-forest&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8825</th>\n",
       "      <td>55398</td>\n",
       "      <td>2019-07-10 02:46:26</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>&lt;scikit-learn&gt;&lt;clustering&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8826</th>\n",
       "      <td>55399</td>\n",
       "      <td>2019-07-10 03:36:20</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;nlp&gt;&lt;lstm&gt;&lt;word-embeddings&gt;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827</th>\n",
       "      <td>55400</td>\n",
       "      <td>2019-07-10 05:24:25</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>&lt;lstm&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8828</th>\n",
       "      <td>55402</td>\n",
       "      <td>2019-07-10 06:24:42</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;convnet&gt;&lt;con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8829</th>\n",
       "      <td>55404</td>\n",
       "      <td>2019-07-10 06:59:30</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;python&gt;&lt;cross-validation&gt;&lt;s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>55405</td>\n",
       "      <td>2019-07-10 07:13:13</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>&lt;python&gt;&lt;topic-model&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8831</th>\n",
       "      <td>55406</td>\n",
       "      <td>2019-07-10 07:21:40</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>&lt;cnn&gt;&lt;audio-recognition&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832</th>\n",
       "      <td>55408</td>\n",
       "      <td>2019-07-10 07:46:26</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;bigdata&gt;&lt;accuracy&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8833</th>\n",
       "      <td>55409</td>\n",
       "      <td>2019-07-10 08:11:43</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;perceptron&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8834</th>\n",
       "      <td>55413</td>\n",
       "      <td>2019-07-10 09:08:31</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;pca&gt;&lt;dimensionality-reduction&gt;&lt;linear-algebra&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>55414</td>\n",
       "      <td>2019-07-10 09:34:55</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>&lt;keras&gt;&lt;weight-initialization&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8836</th>\n",
       "      <td>55415</td>\n",
       "      <td>2019-07-10 09:45:37</td>\n",
       "      <td>1</td>\n",
       "      <td>212</td>\n",
       "      <td>&lt;python&gt;&lt;visualization&gt;&lt;seaborn&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8837</th>\n",
       "      <td>55416</td>\n",
       "      <td>2019-07-10 09:59:56</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;time-series&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8838</th>\n",
       "      <td>55419</td>\n",
       "      <td>2019-07-10 10:31:23</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>&lt;k-nn&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8839 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        CreationDate  Score  ViewCount  \\\n",
       "0     44419 2019-01-23 09:21:13      1         21   \n",
       "1     44420 2019-01-23 09:34:01      0         25   \n",
       "2     44423 2019-01-23 09:58:41      2       1651   \n",
       "3     44427 2019-01-23 10:57:09      0         55   \n",
       "4     44428 2019-01-23 11:02:15      0         19   \n",
       "5     44430 2019-01-23 11:13:32      0        283   \n",
       "6     44432 2019-01-23 11:17:46      1        214   \n",
       "7     44436 2019-01-23 12:49:39      0          9   \n",
       "8     44437 2019-01-23 13:04:11      0          7   \n",
       "9     44438 2019-01-23 13:16:29      0        584   \n",
       "10    44439 2019-01-23 13:25:24      0         17   \n",
       "11    44440 2019-01-23 14:04:25      0         64   \n",
       "12    44446 2019-01-23 14:55:08      1         73   \n",
       "13    44448 2019-01-23 15:34:39      2        105   \n",
       "14    44449 2019-01-23 15:36:41      1       1212   \n",
       "15    44450 2019-01-23 15:37:08      2        178   \n",
       "16    44454 2019-01-23 16:56:01      0        204   \n",
       "17    44456 2019-01-23 17:29:04      2        188   \n",
       "18    44460 2019-01-23 18:03:18      0         48   \n",
       "19    44463 2019-01-23 18:52:32      1         26   \n",
       "20    44465 2019-01-23 21:19:38      2         30   \n",
       "21    44472 2019-01-24 00:10:24      0         52   \n",
       "22    44474 2019-01-24 00:43:27      2       1810   \n",
       "23    44476 2019-01-24 04:59:16      1       1779   \n",
       "24    44478 2019-01-24 06:33:12      0         36   \n",
       "25    44480 2019-01-24 07:04:40      0         16   \n",
       "26    44482 2019-01-24 07:25:46      2         57   \n",
       "27    44483 2019-01-24 07:58:35      0         17   \n",
       "28    44484 2019-01-24 08:17:31      1         34   \n",
       "29    44489 2019-01-24 09:18:10      0         77   \n",
       "...     ...                 ...    ...        ...   \n",
       "8809  55294 2019-07-08 16:36:30      0        460   \n",
       "8810  55784 2019-07-16 14:32:38      0         10   \n",
       "8811  55785 2019-07-16 14:41:40      1        139   \n",
       "8812  55787 2019-07-16 15:19:34      0         20   \n",
       "8813  55793 2019-07-16 17:45:03      1        612   \n",
       "8814  55795 2019-07-16 19:03:17      1        298   \n",
       "8815  55378 2019-07-09 16:22:00      1         33   \n",
       "8816  55379 2019-07-09 16:22:41     -2         37   \n",
       "8817  55383 2019-07-09 17:55:42      0         18   \n",
       "8818  55385 2019-07-09 18:03:00      0         17   \n",
       "8819  55386 2019-07-09 18:03:05      0         12   \n",
       "8820  55388 2019-07-09 19:17:21      1        105   \n",
       "8821  55390 2019-07-09 19:40:40      1         32   \n",
       "8822  55391 2019-07-09 20:28:14      0         16   \n",
       "8823  55396 2019-07-10 01:38:04      0         41   \n",
       "8824  55397 2019-07-10 02:34:22      0         17   \n",
       "8825  55398 2019-07-10 02:46:26      0         98   \n",
       "8826  55399 2019-07-10 03:36:20      2         68   \n",
       "8827  55400 2019-07-10 05:24:25      1         73   \n",
       "8828  55402 2019-07-10 06:24:42      0         87   \n",
       "8829  55404 2019-07-10 06:59:30      1         98   \n",
       "8830  55405 2019-07-10 07:13:13      0         28   \n",
       "8831  55406 2019-07-10 07:21:40      1         34   \n",
       "8832  55408 2019-07-10 07:46:26      0          9   \n",
       "8833  55409 2019-07-10 08:11:43      1         50   \n",
       "8834  55413 2019-07-10 09:08:31      1         39   \n",
       "8835  55414 2019-07-10 09:34:55      0        113   \n",
       "8836  55415 2019-07-10 09:45:37      1        212   \n",
       "8837  55416 2019-07-10 09:59:56      0         22   \n",
       "8838  55419 2019-07-10 10:31:23      1        168   \n",
       "\n",
       "                                                   Tags  AnswerCount  \n",
       "0                       <machine-learning><data-mining>            0  \n",
       "1     <machine-learning><regression><linear-regressi...            0  \n",
       "2          <python><time-series><forecast><forecasting>            0  \n",
       "3                 <machine-learning><scikit-learn><pca>            1  \n",
       "4              <dataset><bigdata><data><speech-to-text>            0  \n",
       "5                                         <fuzzy-logic>            1  \n",
       "6     <time-series><anomaly-detection><online-learning>            0  \n",
       "7                                <matrix-factorisation>            0  \n",
       "8                 <correlation><naive-bayes-classifier>            0  \n",
       "9     <machine-learning><python><deep-learning><kera...            1  \n",
       "10                                   <machine-learning>            0  \n",
       "11                           <machine-learning><theory>            2  \n",
       "12                 <machine-learning><gradient-descent>            2  \n",
       "13    <nlp><clustering><feature-extraction><encoding...            0  \n",
       "14                <python><scikit-learn><pandas><numpy>            0  \n",
       "15    <python><scikit-learn><decision-trees><accurac...            2  \n",
       "16                                     <python><pandas>            2  \n",
       "17                       <python><deep-learning><keras>            1  \n",
       "18    <machine-learning><reinforcement-learning><q-l...            1  \n",
       "19    <neural-network><deep-learning><image-classifi...            0  \n",
       "20             <r><logistic-regression><regularization>            1  \n",
       "21    <machine-learning><time-series><predictive-mod...            0  \n",
       "22                     <python><keras><tensorflow><gpu>            2  \n",
       "23             <python><pandas><bigdata><data-cleaning>            2  \n",
       "24    <machine-learning><data-cleaning><logistic-reg...            1  \n",
       "25                           <python><object-detection>            0  \n",
       "26    <machine-learning><recommender-system><supervi...            1  \n",
       "27    <machine-learning><deep-learning><nlp><text-mi...            0  \n",
       "28                             <machine-learning-model>            1  \n",
       "29                              <xgboost><apache-spark>            0  \n",
       "...                                                 ...          ...  \n",
       "8809  <machine-learning><python><neural-network><ker...            1  \n",
       "8810  <feature-engineering><feature-construction><fe...            0  \n",
       "8811                                       <q-learning>            1  \n",
       "8812                       <r><time-series><statistics>            0  \n",
       "8813    <machine-learning><python><scikit-learn><numpy>            1  \n",
       "8814    <machine-learning><deep-learning><scikit-learn>            1  \n",
       "8815                    <keras><cnn><image-recognition>            2  \n",
       "8816                                       <regression>            3  \n",
       "8817  <classification><feature-selection><feature-en...            0  \n",
       "8818                                             <lstm>            0  \n",
       "8819                         <machine-learning><r><gbm>            0  \n",
       "8820        <keras><regression><xgboost><loss-function>            1  \n",
       "8821  <machine-learning><scikit-learn><random-forest...            1  \n",
       "8822                        <python><keras><tensorflow>            0  \n",
       "8823         <machine-learning><cnn><data-augmentation>            1  \n",
       "8824      <machine-learning><regression><random-forest>            1  \n",
       "8825                         <scikit-learn><clustering>            0  \n",
       "8826  <machine-learning><nlp><lstm><word-embeddings>...            1  \n",
       "8827                                             <lstm>            1  \n",
       "8828  <machine-learning><deep-learning><convnet><con...            1  \n",
       "8829  <machine-learning><python><cross-validation><s...            0  \n",
       "8830                              <python><topic-model>            0  \n",
       "8831                           <cnn><audio-recognition>            1  \n",
       "8832                                <bigdata><accuracy>            0  \n",
       "8833      <machine-learning><deep-learning><perceptron>            1  \n",
       "8834    <pca><dimensionality-reduction><linear-algebra>            1  \n",
       "8835                     <keras><weight-initialization>            0  \n",
       "8836                   <python><visualization><seaborn>            1  \n",
       "8837                                      <time-series>            0  \n",
       "8838                                             <k-nn>            1  \n",
       "\n",
       "[8839 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The Tags Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the Tags column are strings that look like this:\n",
    "\n",
    "\"<machine-learning><regression><linear-regression><regularization>\"\n",
    "\n",
    "We'll want to transform this string in something more suitable to use typical string methods. Our goal will be to transform strings like the above in something like:\n",
    "\n",
    "\"machine-learning,regression,linear-regression,regularization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split all the tags in each post into five columns\n",
    "tag_columns = ['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']\n",
    "questions_clean[tag_columns] = (questions_clean.Tags.str.replace('<', '')\n",
    "                                                        .str.rstrip('>')\n",
    "                                                        .str.split('>', expand=True)\n",
    "                               )\n",
    "# Drop the Tags column\n",
    "questions_clean.drop(columns = 'Tags', inplace=True)\n",
    "\n",
    "# Condense all Tags into two columns\n",
    "questions_clean = pd.melt(questions_clean, \n",
    "                          id_vars=['Id', 'CreationDate', 'Score', 'ViewCount', 'AnswerCount'],\n",
    "                          value_vars = tag_columns, \n",
    "                          var_name= 'TagNumber', \n",
    "                          value_name= 'TagName'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>TagNumber</th>\n",
       "      <th>TagName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44419</td>\n",
       "      <td>2019-01-23 09:21:13</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Tag1</td>\n",
       "      <td>machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44420</td>\n",
       "      <td>2019-01-23 09:34:01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Tag1</td>\n",
       "      <td>machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44423</td>\n",
       "      <td>2019-01-23 09:58:41</td>\n",
       "      <td>2</td>\n",
       "      <td>1651</td>\n",
       "      <td>0</td>\n",
       "      <td>Tag1</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44427</td>\n",
       "      <td>2019-01-23 10:57:09</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>Tag1</td>\n",
       "      <td>machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44428</td>\n",
       "      <td>2019-01-23 11:02:15</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Tag1</td>\n",
       "      <td>dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        CreationDate  Score  ViewCount  AnswerCount TagNumber  \\\n",
       "0  44419 2019-01-23 09:21:13      1         21            0      Tag1   \n",
       "1  44420 2019-01-23 09:34:01      0         25            0      Tag1   \n",
       "2  44423 2019-01-23 09:58:41      2       1651            0      Tag1   \n",
       "3  44427 2019-01-23 10:57:09      0         55            1      Tag1   \n",
       "4  44428 2019-01-23 11:02:15      0         19            0      Tag1   \n",
       "\n",
       "            TagName  \n",
       "0  machine-learning  \n",
       "1  machine-learning  \n",
       "2            python  \n",
       "3  machine-learning  \n",
       "4           dataset  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the resulting dataframe\n",
    "questions_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3. ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on determining the most popular tags. We'll do so by considering two different popularity proxies: for each tag we'll count how many times the tag was used, and how many times a question with that tag was viewed.\n",
    "\n",
    "We could take into account the score, or whether or not a question is part of someone's favorite questions. These are all reasonable options to investigate; but we'll limit the focus of our research to counts and views for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to find out how many times each individual tag was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the use frequency of each tag\n",
    "tag_counts = questions_clean.groupby('TagName').size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Compute the total views, scores, answers and favorites by TagName\n",
    "\n",
    "col_dict = {\n",
    "    # Stores the columns of interest and their aggregate column names\n",
    "    \"cols\": ['Score', 'ViewCount', 'AnswerCount'],\n",
    "    \"aggregate_names\": ['total_score', 'total_views', 'total_answers']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute relevant totals for each unique TagName\n",
    "aggregate_df = questions_clean.groupby('TagName')[col_dict['cols']].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename resulting columns with their aggregate names\n",
    "aggregate_df.columns = col_dict['aggregate_names']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update dataframe with the count of each tag\n",
    "aggregate_df['count'] = tag_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_score</th>\n",
       "      <th>total_views</th>\n",
       "      <th>total_answers</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TagName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine-learning</th>\n",
       "      <td>2515</td>\n",
       "      <td>388499</td>\n",
       "      <td>2313</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1475</td>\n",
       "      <td>537585</td>\n",
       "      <td>1507</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning</th>\n",
       "      <td>1127</td>\n",
       "      <td>233628</td>\n",
       "      <td>877</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural-network</th>\n",
       "      <td>1021</td>\n",
       "      <td>185367</td>\n",
       "      <td>824</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras</th>\n",
       "      <td>785</td>\n",
       "      <td>268608</td>\n",
       "      <td>654</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>701</td>\n",
       "      <td>104457</td>\n",
       "      <td>651</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tensorflow</th>\n",
       "      <td>417</td>\n",
       "      <td>121369</td>\n",
       "      <td>353</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learn</th>\n",
       "      <td>507</td>\n",
       "      <td>128110</td>\n",
       "      <td>518</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp</th>\n",
       "      <td>455</td>\n",
       "      <td>71382</td>\n",
       "      <td>369</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>452</td>\n",
       "      <td>70349</td>\n",
       "      <td>362</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  total_score  total_views  total_answers  count\n",
       "TagName                                                         \n",
       "machine-learning         2515       388499           2313   2693\n",
       "python                   1475       537585           1507   1814\n",
       "deep-learning            1127       233628            877   1220\n",
       "neural-network           1021       185367            824   1055\n",
       "keras                     785       268608            654    935\n",
       "classification            701       104457            651    685\n",
       "tensorflow                417       121369            353    584\n",
       "scikit-learn              507       128110            518    540\n",
       "nlp                       455        71382            369    493\n",
       "cnn                       452        70349            362    489"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview results sorted by count\n",
    "aggregate_df.sort_values(by='count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "Machine learning, Python and Deep learning seem like the most popular tags on all levels. They have gathered the highest frequency of use, views, answers, and upvotes.\n",
    "\n",
    "It seems that as the frequency of use (count) decreases, other measures decrease as well. This suggests a possible positive corellation between the count column and all other measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further investigate these observations, we can examine the relationship between the count column and other columns. \n",
    "\n",
    "In addition, we will visualize the popularity of the leading tags (suspected at this point), relative to other tags used on the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 4))\n",
    "\n",
    "facets = col_dict['aggregate_names']\n",
    "leading_tags = ['machine-learning', 'python', 'deep-learning']\n",
    "\n",
    "# Generate count vs measure plots\n",
    "for index, col in zip(range(3), facets):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    sns.regplot(data=aggregate_df, x='count', y=col, \n",
    "                color='#444444', ci=False)  # Updated color value\n",
    "    \n",
    "    plt.scatter(data=aggregate_df.loc[leading_tags], \n",
    "                x='count', y=col, c='#0064AB')\n",
    "    \n",
    "    # Annotate the leading tags\n",
    "    for tag in leading_tags:\n",
    "        plt.text(x=aggregate_df.loc[tag, 'count'] - 60, \n",
    "                 y=aggregate_df.loc[tag, col] - aggregate_df[col].max() / 100,\n",
    "                 s=tag.replace('-', ' ').title(), alpha=0.9,\n",
    "                 fontsize=8, color='#0064AB', fontweight='bold', \n",
    "                 ha='right')\n",
    "        \n",
    "    y_ticks = [0, int(aggregate_df[col].max() / 2), aggregate_df[col].max()]\n",
    "    x_ticks = range(0, 3500, 1000)\n",
    "    plt.xticks(x_ticks, [\"{}k\".format(t // 1000) if t > 0 else t for t in x_ticks], \n",
    "               color='gray', fontsize=8)\n",
    "    plt.yticks(y_ticks, [\"{}k\".format(t // 1000) if t > 0 else t for t in y_ticks], \n",
    "               color='gray', fontsize=8)\n",
    "    plt.xlabel('count', fontsize='9', fontweight='bold', alpha=0.3)\n",
    "    plt.ylabel(col, fontsize='9', fontweight='bold', alpha=0.3)\n",
    "    plt.title('Popularity and {}'.format(col.split('_')[1].title()), weight='bold', alpha=0.4)\n",
    "    \n",
    "# Set attributes common to all plots\n",
    "axes_list = fig.get_axes()\n",
    "for ax in axes_list:\n",
    "    for loc in ['left', 'bottom', 'top', 'right']:\n",
    "        ax.spines[loc].set_color('#DDDDDD')  # Updated color value\n",
    "    ax.tick_params(left=False, bottom=False)\n",
    "    sns.despine()\n",
    "\n",
    "# Plot title\n",
    "axes_list[0].text(x=-100, y=2500, fontsize=20, fontweight='bold', alpha=0.7,\n",
    "                  s='Most Popular DSSE Tags', color='#0064AB')\n",
    "\n",
    "axes_list[0].text(x=3500, y=2500, fontsize=20, fontweight='bold', color=\"#444444\",\n",
    "                  s='vs Other Tags')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "Our initial observation is confirmed. Machine Learning, Python and Deep Learning are the three most popular tags used on the site. \n",
    "\n",
    "This is apparent based on their position in the upper right of each chart. Machine learning also shows a greater level of popularity than the other two tags.\n",
    "\n",
    "In addition, there is a positive correlation between the frequency of use and every other measure. It is clear that the most popular topics get the highest number of views, upvotes and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Relations Between Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags present in most_used and not present in most_viewed are:\n",
    "\n",
    "machine-learning-model\n",
    "statistics\n",
    "predictive-modeling\n",
    "r\n",
    "And the tags present in most_viewed but not in most_used are:\n",
    "\n",
    "csv\n",
    "pytorch\n",
    "dataframe\n",
    "\n",
    "Some tags also stand out as being related. For example, python is related to pandas, as we can find both pythons and pandas in the same country — or better yet, because pandas is a Python library. So by writing about pandas, we can actually simultaneously tackle two tags\n",
    "\n",
    "\n",
    "\n",
    "Earlier, we identified the three leading tags based on different measures of popularity. Determining how these popular tags relate to one another would be beneficial. Our question is: do people combine these tags in their posts? If yes, which popular tags are commonly used together?\n",
    "\n",
    "To address these questions, we will consider the top ten tags based on use frequency or count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 machine-learning\n",
      "2 python\n",
      "3 deep-learning\n",
      "4 neural-network\n",
      "5 keras\n",
      "6 classification\n",
      "7 tensorflow\n",
      "8 scikit-learn\n",
      "9 nlp\n",
      "10 cnn\n"
     ]
    }
   ],
   "source": [
    "# Identify the most popular tags by count\n",
    "popular_tags = (aggregate_df.sort_values(by='count', ascending=False)\n",
    "                            .head(10)\n",
    "                            .index\n",
    "               )\n",
    "\n",
    "for position, tag in enumerate(popular_tags):\n",
    "    print(position+1, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a dataframe that will contain the number of times that these tags were used together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine-learning</th>\n",
       "      <th>python</th>\n",
       "      <th>deep-learning</th>\n",
       "      <th>neural-network</th>\n",
       "      <th>keras</th>\n",
       "      <th>classification</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>scikit-learn</th>\n",
       "      <th>nlp</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine-learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural-network</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  machine-learning  python  deep-learning  neural-network  \\\n",
       "machine-learning                 0       0              0               0   \n",
       "python                           0       0              0               0   \n",
       "deep-learning                    0       0              0               0   \n",
       "neural-network                   0       0              0               0   \n",
       "keras                            0       0              0               0   \n",
       "\n",
       "                  keras  classification  tensorflow  scikit-learn  nlp  cnn  \n",
       "machine-learning      0               0           0             0    0    0  \n",
       "python                0               0           0             0    0    0  \n",
       "deep-learning         0               0           0             0    0    0  \n",
       "neural-network        0               0           0             0    0    0  \n",
       "keras                 0               0           0             0    0    0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = pd.DataFrame(index= list(popular_tags), \n",
    "                            columns= list(popular_tags)\n",
    "                           )\n",
    "combinations.fillna(0, inplace= True)\n",
    "combinations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will populate the table with the number of times each tag is used in combination with another. We will not count instances where a tag is used in isolation since that would be redundant for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Isolate records for the 10 popular tags\n",
    "popular_tags_df = questions_clean.query('TagName in @popular_tags')\n",
    "\n",
    "# Pivot the dataframe to view tag combinations\n",
    "popular_tags_df = popular_tags_df.pivot(index='Id', \n",
    "                                        columns='TagNumber', \n",
    "                                        values = 'TagName'\n",
    "                                       )\n",
    "\n",
    "# Count the different tag combinations\n",
    "for first_tag, index in zip(popular_tags_df.Tag1, popular_tags_df.index):\n",
    "    for col in ['Tag2', 'Tag3', 'Tag4', 'Tag5']:\n",
    "        next_tag = popular_tags_df.loc[index, col]\n",
    "        if not(pd.isnull(next_tag)) and not(pd.isnull(first_tag)):\n",
    "            combinations.loc[first_tag, next_tag] += 1\n",
    "            combinations.loc[next_tag, first_tag] += 1\n",
    "            \n",
    "# Visualize results with a heatmap\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "ax = sns.heatmap(data=combinations, annot=True, fmt='0', cmap='Blues',\n",
    "            cbar=False, linewidth=1)\n",
    "\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.tick_params(left=False, top=False)\n",
    "\n",
    "plt.xticks(fontsize=7, fontweight='bold')\n",
    "plt.yticks(fontsize=9, alpha=0.5, fontweight='bold')\n",
    "\n",
    "plt.title('How the most popular tags are combined', alpha=0.5, fontsize=16, loc='left', fontweight='bold')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.text(x=0, y=-1.2, s='Each box represents the number of cases', \n",
    "         color = '#0064AB', fontweight='bold', alpha=0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "The most popular tags (Machine Learning, Python and Deep Learning) appear to have the strongest associations. They are used together than any other popular tag.\n",
    "\n",
    "Machine learning is also used frequently with other tags like Classification, neural network and NLP.\n",
    "\n",
    "Our findings are becoming interesting at this point. We identified Machine learning as the most popular tag and then discovered that many other popular tags are used together with it. \n",
    "\n",
    "At this point, exploring external sources for information on all these tags would be helpful, especially how they relate to one another in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engaging Domain Knowledge\n",
    "Collecting information from the DSSE website, as well as other external sources yields the following information on the most popular tags.\n",
    "\n",
    "Machine Learning: A subfield of computer science that draws on elements from algorithmic analysis, computational statistics, mathematics, optimization, etc. It is mainly concerned with the use of data to construct models that have high predictive/forecasting ability (source).\n",
    "\n",
    "Deep learning: A new area of Machine Learning research concerned with the technologies used for learning hierarchical representations of data, mainly done with deep neural networks (i.e. networks with two or more hidden layers), but also with some sort of Probabilistic Graphical Models (source).\n",
    "\n",
    "Neural networks: Neural networks make up the backbone of deep learning algorithms. Specifically called artificial neural networks (ANNs), they are designed to mimic the human brain through a set of algorithms (source).\n",
    "\n",
    "Natural Language Processing (NLP): Involves using machine learning , deep learning (in recent trends) algorithms and “narrow” artificial intelligence (AI) to understand the meaning of text documents (source).\n",
    "\n",
    "Classification: A subset of machine learning (supervised learning), that identifies the category or categories which a new instance of dataset belongs (source).\n",
    "\n",
    "TensorFlow: TensorFlow is an open source library for machine learning , deep learning and machine intelligence (source).\n",
    "\n",
    "Keras: A popular, open-source deep learning API for Python built on top of TensorFlow and is useful for fast implementation (source).\n",
    "Scikit-learn: A popular machine learning package for Python that has simple and efficient tools for predictive data analysis (source).\n",
    "Information on Python* and Time series is intentionally ommitted since they are quite generic.*\n",
    "\n",
    "Most of the top tags are associated with machine learning in one way or another. This explains our earlier observation, where most of the tags were combined with machine learning. Since machine learning is a broad field, and python could be generic to many applications, the interesting topic here appears to be the relatively narrower alternative - Deep learning.\n",
    "\n",
    "In otherwords, we can say that the most popular topic on DSSE from year 2021 till date is deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Deep Learning Just A Fad?\n",
    "Before we communicate our recommendation, it is important to ensure that our findings are backed with proof. Ideally, we want the content we create to be relevant and useful for as long as possible. To ensure this, we need to identify if people's interest in deep learning is increasing overtime or slowing down.\n",
    "\n",
    "To address this question, we will pull information on all questions from DSSE till date. Relevant information will be the Id of the question, the CreationDate and the Tags used. The query below serves this purpose:\n",
    "\n",
    "        SELECT Id, \n",
    "               CreationDate, \n",
    "               Tags\n",
    "          FROM posts\n",
    "         WHERE PostTypeId = 1\n",
    "         ORDER BY CreationDate;\n",
    "The output of the query has been stored in a local file named all_questions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we will track the interest in deep learning across time. We will:\n",
    "\n",
    "Count how many deep learning questions are asked per time period.\n",
    "The total amount of questions per time period.\n",
    "How many deep learning questions there are relative to the total amount of questions per time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45416</td>\n",
       "      <td>2019-02-12 00:36:29</td>\n",
       "      <td>&lt;python&gt;&lt;keras&gt;&lt;tensorflow&gt;&lt;cnn&gt;&lt;probability&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45418</td>\n",
       "      <td>2019-02-12 00:50:39</td>\n",
       "      <td>&lt;neural-network&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45422</td>\n",
       "      <td>2019-02-12 04:40:51</td>\n",
       "      <td>&lt;python&gt;&lt;ibm-watson&gt;&lt;chatbot&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45426</td>\n",
       "      <td>2019-02-12 04:51:49</td>\n",
       "      <td>&lt;keras&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45427</td>\n",
       "      <td>2019-02-12 05:08:24</td>\n",
       "      <td>&lt;r&gt;&lt;predictive-modeling&gt;&lt;machine-learning-mode...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        CreationDate  \\\n",
       "0  45416 2019-02-12 00:36:29   \n",
       "1  45418 2019-02-12 00:50:39   \n",
       "2  45422 2019-02-12 04:40:51   \n",
       "3  45426 2019-02-12 04:51:49   \n",
       "4  45427 2019-02-12 05:08:24   \n",
       "\n",
       "                                                Tags  \n",
       "0      <python><keras><tensorflow><cnn><probability>  \n",
       "1                                   <neural-network>  \n",
       "2                      <python><ibm-watson><chatbot>  \n",
       "3                                            <keras>  \n",
       "4  <r><predictive-modeling><machine-learning-mode...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and preview the local file\n",
    "all_questions = pd.read_csv('./all_questions.csv', parse_dates=['CreationDate'])\n",
    "all_questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's expand the Tags column to make the data easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45416</td>\n",
       "      <td>2019-02-12 00:36:29</td>\n",
       "      <td>python</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45418</td>\n",
       "      <td>2019-02-12 00:50:39</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45422</td>\n",
       "      <td>2019-02-12 04:40:51</td>\n",
       "      <td>python</td>\n",
       "      <td>ibm-watson</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        CreationDate            Tag1        Tag2        Tag3  Tag4  \\\n",
       "0  45416 2019-02-12 00:36:29          python       keras  tensorflow   cnn   \n",
       "1  45418 2019-02-12 00:50:39  neural-network        None        None  None   \n",
       "2  45422 2019-02-12 04:40:51          python  ibm-watson     chatbot  None   \n",
       "\n",
       "          Tag5  \n",
       "0  probability  \n",
       "1         None  \n",
       "2         None  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand tags into seperate columns\n",
    "all_questions[tag_columns] = (all_questions.Tags.str.replace('<', '')\n",
    "                                                .str.rstrip('>')\n",
    "                                                .str.split('>', expand=True)\n",
    "                             )\n",
    "# Drop the original Tags column\n",
    "all_questions.drop(columns = 'Tags', inplace=True)\n",
    "all_questions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to identify tags that are related to Deep learning.\n",
    "At the same time, we are also concerned about popularity. To combine our interests, we will follow a two step process:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the 20 most popular tags.\n",
    "\n",
    "\n",
    "From the top 20, find tags that are related to deep learning.\n",
    "1. Identify the 20 most popular tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 machine-learning\n",
      "2 python\n",
      "3 deep-learning\n",
      "4 neural-network\n",
      "5 keras\n",
      "6 classification\n",
      "7 tensorflow\n",
      "8 scikit-learn\n",
      "9 nlp\n",
      "10 cnn\n",
      "11 time-series\n",
      "12 lstm\n",
      "13 pandas\n",
      "14 regression\n",
      "15 dataset\n",
      "16 r\n",
      "17 predictive-modeling\n",
      "18 clustering\n",
      "19 statistics\n",
      "20 machine-learning-model\n"
     ]
    }
   ],
   "source": [
    "top_20 = aggregate_df.sort_values(by='count', ascending=False).head(20)\n",
    "for num, tag in enumerate(top_20.index):\n",
    "    print(num+1, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. From the top 20, find tags that are related to Deeplearning\n",
    "A quick online research on each of the top 20 tags reveals the following as related to deep learning:\n",
    "\n",
    "\"lstm\", \"cnn\", \"scikit-learn\", \"tensorflow\", \"keras\", \"neural-network\", \"deep-learning\", \n",
    "\"convolutional-neural-network\" and \"pytorch\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any tag that belongs to this list will be classified as a deep learning tag. We can reflect this classification in our dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dl_tags = [\"lstm\", \"cnn\", \"scikit-learn\", \"tensorflow\",\n",
    "           \"keras\", \"neural-network\", \"deep-learning\",\n",
    "           \"convolutional-neural-network\", \"pytorch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>is_deeplearning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>46830</td>\n",
       "      <td>2019-03-07 05:07:47</td>\n",
       "      <td>regression</td>\n",
       "      <td>grid-search</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>1075</td>\n",
       "      <td>2014-09-04 18:13:57</td>\n",
       "      <td>apache-hadoop</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>25771</td>\n",
       "      <td>2017-12-18 12:34:01</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>convnet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>6398</td>\n",
       "      <td>2015-07-08 20:57:09</td>\n",
       "      <td>python</td>\n",
       "      <td>pandas</td>\n",
       "      <td>linear-regression</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10072</th>\n",
       "      <td>8697</td>\n",
       "      <td>2015-11-03 06:26:49</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>data-mining</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id        CreationDate              Tag1            Tag2  \\\n",
       "3219   46830 2019-03-07 05:07:47        regression     grid-search   \n",
       "2697    1075 2014-09-04 18:13:57     apache-hadoop            None   \n",
       "3079   25771 2017-12-18 12:34:01  machine-learning  neural-network   \n",
       "7500    6398 2015-07-08 20:57:09            python          pandas   \n",
       "10072   8697 2015-11-03 06:26:49  machine-learning     data-mining   \n",
       "\n",
       "                    Tag3  Tag4  Tag5  is_deeplearning  \n",
       "3219                None  None  None            False  \n",
       "2697                None  None  None            False  \n",
       "3079             convnet  None  None             True  \n",
       "7500   linear-regression  None  None            False  \n",
       "10072               None  None  None            False  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign True to deep learning posts and False otherwise \n",
    "all_questions['is_deeplearning'] = all_questions.iloc[:, 2:].isin(dl_tags).any(axis=1)\n",
    "all_questions.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trends In Deep Learning Posts Overtime\n",
    "We currently have data spanning from 2014 till date (about 8 years). If we decide to track trends monthly, we will have too many data points to consider. Tracking yearly will also give few data points. We will consider the more appropriate alternative: tracking trends quarterly.\n",
    "\n",
    "Note:\n",
    "\n",
    "At the time of this writing (February, 2023), we do not have all the data for the first quarter of 2023.\n",
    "For consistency, we will remove all records for Q1, 2023 from our dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019Q1', '2014Q2', '2018Q3', '2019Q3', '2017Q4', '2016Q4',\n",
       "       '2014Q3', '2017Q1', '2014Q4', '2018Q1', '2015Q1', '2018Q4',\n",
       "       '2015Q2', '2019Q2', '2017Q2', '2015Q3', '2015Q4', '2019Q4',\n",
       "       '2018Q2', '2017Q3', '2016Q1', '2016Q2', '2016Q3', '2020Q1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the quarter from the creation date column\n",
    "all_questions['quarter'] = pd.PeriodIndex(all_questions.CreationDate, freq='Q')\n",
    "all_questions['quarter'] = all_questions['quarter'].astype(str)\n",
    "\n",
    "# Remove records for Q1, 2023\n",
    "all_questions = all_questions.query('quarter != \"2023Q1\"')\n",
    "all_questions.quarter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>is_deeplearning</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>22796</td>\n",
       "      <td>2017-09-03 15:04:51</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>classification</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2017Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>38868</td>\n",
       "      <td>2018-09-27 15:50:55</td>\n",
       "      <td>python</td>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2018Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>15305</td>\n",
       "      <td>2016-11-23 09:46:50</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2016Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>64048</td>\n",
       "      <td>2019-12-01 00:32:11</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2019Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14727</th>\n",
       "      <td>44416</td>\n",
       "      <td>2019-01-23 07:37:38</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>keras</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2019Q1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id        CreationDate              Tag1                 Tag2  \\\n",
       "14887  22796 2017-09-03 15:04:51  machine-learning       classification   \n",
       "4313   38868 2018-09-27 15:50:55            python  logistic-regression   \n",
       "1509   15305 2016-11-23 09:46:50           xgboost                 None   \n",
       "17940  64048 2019-12-01 00:32:11             keras           tensorflow   \n",
       "14727  44416 2019-01-23 07:37:38  machine-learning                keras   \n",
       "\n",
       "                Tag3                  Tag4  Tag5  is_deeplearning quarter  \n",
       "14887  deep-learning  image-classification  None             True  2017Q3  \n",
       "4313        accuracy                  None  None            False  2018Q3  \n",
       "1509            None                  None  None            False  2016Q4  \n",
       "17940           None                  None  None             True  2019Q4  \n",
       "14727           None                  None  None             True  2019Q1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our dataframe organized in this format, we can group questions by quarter, then compute the proportion of deep learning questions relative to all questions posted on DSSE. From the resulting dataframe, we can build visuals that communicate deep learning trends overtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>dl_questions</th>\n",
       "      <th>all_questions</th>\n",
       "      <th>dl_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014Q2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>157</td>\n",
       "      <td>0.057325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014Q3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>189</td>\n",
       "      <td>0.068783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014Q4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0.097222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015Q1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>190</td>\n",
       "      <td>0.094737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015Q2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>284</td>\n",
       "      <td>0.098592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter  dl_questions  all_questions  dl_proportion\n",
       "0  2014Q2           9.0            157       0.057325\n",
       "1  2014Q3          13.0            189       0.068783\n",
       "2  2014Q4          21.0            216       0.097222\n",
       "3  2015Q1          18.0            190       0.094737\n",
       "4  2015Q2          28.0            284       0.098592"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of deep learning and total questions by quarter\n",
    "by_quarter = all_questions.groupby('quarter').agg({'is_deeplearning': ['sum', 'size']})\n",
    "\n",
    "# Assign names to the resulting columns\n",
    "by_quarter.columns = ['dl_questions', 'all_questions']\n",
    "\n",
    "# Compute the proportion of deep learning questions per quarter\n",
    "by_quarter['dl_proportion'] = (by_quarter['dl_questions']/by_quarter['all_questions'])\n",
    "by_quarter.reset_index(inplace=True)\n",
    "by_quarter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Identify start and end deep learning proportion\n",
    "end_proportion = by_quarter.iloc[-1, 3]\n",
    "start_proportion = by_quarter.iloc[0, 3]\n",
    "\n",
    "# Convert 'quarter' column to datetime type\n",
    "by_quarter['quarter'] = pd.to_datetime(by_quarter['quarter'])\n",
    "\n",
    "# Base figure\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "quarters = by_quarter['quarter']\n",
    "plt.plot(quarters, by_quarter['dl_proportion'], color='#0064AB', linewidth=3)\n",
    "plt.scatter(x=[quarters.iloc[0], quarters.iloc[-1]], y=[start_proportion, end_proportion], color='#0064AB')\n",
    "\n",
    "# Ticks and labels\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(np.arange(0, 0.6, 0.1), ['0%', '10%', '20%', '30%', '40%', '50%'], color='#AAA')\n",
    "plt.xlabel('Year', color='#AAA', fontsize=10, weight='bold')\n",
    "plt.ylabel('Deep learning percentage', color='#AAA', fontsize=10, weight='bold')\n",
    "\n",
    "# Plot title and dividers\n",
    "plt.title('Deep learning: just a fad?', color='#555', size=18, loc='left')\n",
    "plt.axhline(y=0.3, alpha=0.1, linewidth=1)\n",
    "plt.axvline(x=pd.Timestamp('2016-01-01'), linewidth=1, color='#BABABA')\n",
    "\n",
    "# Annotations\n",
    "plt.text(x=pd.Timestamp('2015-07-01'), y=0.54, color='#888', size=12,\n",
    "         s='Percentage of deep learning questions relative to the total questions on DSSE')\n",
    "plt.text(x=pd.Timestamp('2016-04-01'), y=0.18, s='Since 2016, Deep learning\\nhas accounted for over 30% '\n",
    "         +'of\\nthe questions posted on\\nData Science Stack Exchange.', size=10,\n",
    "        color='#0064AB', weight='bold')\n",
    "for loc, prop in zip([quarters.iloc[0], quarters.iloc[-1]], [start_proportion, end_proportion]):\n",
    "    plt.text(x=loc, y=prop+0.025, s='{}%'.format(int(prop*100)),\n",
    "             color='#0064AB', weight='bold', size=14)\n",
    "\n",
    "# Declutter plot\n",
    "ax = fig.get_axes()[0]\n",
    "for loc in ['left', 'bottom', 'top', 'right']:\n",
    "    ax.spines[loc].set_color('#DDDDDD')  # Updated color value\n",
    "ax.tick_params(bottom=False, left=False)\n",
    "sns.despine()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "The percentage of deep learning questions grew drastically between 2014 (5%) and 2016 (over 30%). Though this growth appears to have plateaued, the proportion has been maintained above 30% from 2016 to date (about six years). It is clear from this observation that deep learning is not just a fad. It is a growing field of data science that sparked a strong initial interest and is still explored on DSSE to date.\n",
    "Conclusion\n",
    "Throughout this project, we collected, explored and analyzed data from the Data Science Stack Exchange (DSSE) Database. Our goal was to identify the most popular Data science topic and then use the insight to develop content that our audience will engage with and love.\n",
    "\n",
    "Analysis showed machine learning, python and deep learning as the most popular data science topics. However, due to the broad nature of the earlier two options, we decided to focus on the relatively narrower alternative - deep learning.\n",
    "\n",
    "Interestingly, deep learning has grown in popularity on DSSE, rising from over 5% of total DSSE questions in 2014 to over 30% in 2016. Deep learning still accounts for over 30% of questions posted on DSSE to date, signifying that the topic is not just a fad. Instead, it is a growing field of data science that people continue to engage and explore over the long term.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Recommendations and Limitations\n",
    "Based on our discovery, we advise tailoring our resources to address deep learning content since it promises a potential for audience interaction and engagement in the data science space.\n",
    "Although our research has allowed us to conclude that deep learning is the most popular topic, our insight is from a single source. We could explore data from other data science sites to gain more confidence in our findings.\n",
    "Considering non-data-science content to write about can also give us a potential for diversification since it enables us to appeal to a larger audience in the long run.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
